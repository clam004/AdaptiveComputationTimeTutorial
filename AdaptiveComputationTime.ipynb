{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>Adaptive Computation Time for Recurrent Neural Networks</center></h1>\n",
    "\n",
    "\n",
    "<h13><center>Alex Graves 2017 </center></h13>\n",
    "<h13><center>DeepMind</center></h13>\n",
    "\n",
    "<h13><center> Presentation to Enlitic by Carson Lam  </center></h13>\n",
    "\n",
    "[Arxiv link](https://arxiv.org/pdf/1603.08983.pdf) \n",
    "\n",
    "[GitHub](https://github.com/zphang/adaptive-computation-time-pytorch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background: Vanilla Recurrent Neural Network (RNN)\n",
    "\n",
    "<img src=\"https://miro.medium.com/max/1168/1*SBeZvxdxhnL5zqvKfyLGRQ.png\" width =500>\n",
    "\n",
    "<img src=\"https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQLBJa0HXfrvlgQIZgNkzHWRquWdWAf-gGws6UwUnHFqzk8DSLH&s\">\n",
    "\n",
    "vertical dotted lines represent the separation between time steps \n",
    "\n",
    " s_t is the RNN sate state at timepoint t. s_t = S(s_t - 1, x_t) is a state transition operation aka one layer of a recurrent neural network. s_t is passed to the next timestep t. \n",
    "\n",
    "s_t is often given the variable h_t for hidden state in other writings, here h is reserved for another value\n",
    "\n",
    "<img src=\"http://karpathy.github.io/assets/rnn/charseq.jpeg\" width =500>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One example of a state transition operation is the Gated Recurrent Unit\n",
    "\n",
    "$$ z_{t} = \\sigma(W^{z} x_{t} + U^{z} s_{t-1}) $$\n",
    "\n",
    "z (update gate): when z ~ 1, the previous state is copied over to the current state,\n",
    "when z ~ 0 the updated state replaces the previous state \n",
    "\n",
    "$$ r_{t} = \\sigma(W^{r} x_{t} + U^{r} s_{t-1}) $$\n",
    "\n",
    "r (reset gate): the closer r is to 1, the more the prevous state is used to inform the updated state\n",
    "\n",
    "$$  \\tilde{s_{t}} = tanh(W^{s} x_{t} + r_{t} \\odot U^{s} s_{t-1} ) $$\n",
    "\n",
    "$$ s_{t} = z_{t} \\odot s_{t-1} + (1 - z_{t}) \\odot \\tilde{s_{t}} = S(s_{t - 1}, x_{t}) $$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-Layer RNN\n",
    "\n",
    "<img src=\"https://blog.exxactcorp.com/wp-content/uploads/2019/01/0_iLv3Tisjx68QrYU7-257x300.png\" width=300 >\n",
    "\n",
    "In multi-layer RNNS each of the green states is produced by another set of weights. \n",
    "\n",
    "$$ s^{n}_{t} =  S(s^{n}_{t-1}, s^{n-1}_{t}) $$\n",
    "\n",
    "Where the first layer takes as input x, and the deeper layers (up direction) takes the output of the layer below it as input.\n",
    "\n",
    "$$ s^{0}_{t} = x_{t}$$\n",
    "\n",
    "The depth is fixed so the input is transformed exactly 4 times before it is transformed into the output at each time step t, 3 RNN layers and 1 output layer. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adaptive Computation Time (ACT)\n",
    "\n",
    "In Adaptive Computation Time (ACT), n is for the number of times the same weights are applied repeatedly to update the state. \n",
    "\n",
    "The first of these updates takes as input the state from the previous timestep and the input with binary flag = 0. `[-0.1, 0.5, 1.2, 0]` Subsequent updates take as input the state from the previous update of the same timestep and the input with binary flag = 1, `[-0.1, 0.5, 1.2, 1]`, so that the state transition operation can distinguish between repeat inputs at a subsequent timestep from repeat inputs at a subsequent update.\n",
    "\n",
    "<img src=\"https://miro.medium.com/max/729/1*4pOFTSf6clGBToAriB4i5w.png\" width=400>\n",
    "\n",
    "n is not for the number of layers in a multi-layer RNN where each transformation by a layers weights are performed exactly once for timestep and the weights are not shared between layers. \n",
    "\n",
    "For each timestp t, the input is updated for a variable number of updates n. The number of updates, n, is a learned function of the state at time t, and in turn the input at time t. \n",
    "\n",
    "That learned function is the halting unit, h, not to be confused with hidden state, h is a scalar.\n",
    "\n",
    "<img src=\"https://miro.medium.com/max/489/1*f4PRPGPSnzgEmhdgWd86ow.png\" width=300>\n",
    "\n",
    "The halting unit between 0 and 1, thus the sigmoid, and is accumulated at each state update until the total sum of halthing units exceeds 1 - epsilon.\n",
    "\n",
    "Suppose epsilon = 0.1, then 1 - epsilon = 0.9, then the total number of updates at time t will be N(t) where\n",
    "\n",
    "$$ N(t) = min\\{ n' : \\sum_{n=1}^{n'} h^{n}_{t} >= 1 - \\epsilon \\} $$\n",
    "\n",
    "In the table representation of the halthing units produced at each update 1 thru 4, N(t) = 3, since 0.1 + 0.3 + 0.5 = 0.9, so this timestep would undergo 3 updates. The 4th update wouldve produced a halthing unit of 0.5, but this update is never performed since the updates are stopped once the sum of halting units equals or exceeds 1 - epsilon.\n",
    "\n",
    "<table width=200>\n",
    "    \n",
    "<tr>\n",
    "<th>s</th>\n",
    "<th>h</th>\n",
    "</tr>\n",
    "\n",
    "<tr>\n",
    "<td>4</td>\n",
    "<td>0.5</td>\n",
    "</tr>\n",
    "\n",
    "<tr>\n",
    "<td>3</td>\n",
    "<td>0.5</td>\n",
    "</tr>\n",
    "\n",
    "<tr>\n",
    "<td>2</td>\n",
    "<td>0.3</td>\n",
    "</tr>\n",
    "\n",
    "<tr>\n",
    "<td>1</td>\n",
    "<td>0.1</td>\n",
    "</tr>\n",
    "\n",
    "</table>\n",
    "\n",
    "The diagram below is the ACT version of the RNN diagram we have already seem. It leaves out one informative concept though. That is how the final state s and ouputs y are determined for timestep t. They are mean-field or weighted sum of the intermediate states and ouputs, weighted by p, the halting probabilities. The halting probabilities p  are mostly the same as the halting units  h at each update, except the last update where n = N(t).\n",
    "\n",
    "<img src=\"https://miro.medium.com/max/888/1*SivgPX_-tcrlTuOTs2toEQ.png\" width=400>\n",
    "\n",
    "$$\n",
    "    p^{n}_{t}=\\left\\{\n",
    "                \\begin{array}{ll}\n",
    "                  R(t),\\, if \\; n = N(t)\\\\\n",
    "                  h^{n}_{t} \\, otherwise\n",
    "                \\end{array}\n",
    "              \\right.\n",
    "$$\n",
    "\n",
    "$$ R(t) = 1 -  \\sum_{n=1}^{N(t)-1} h^{n}_{t} $$\n",
    "\n",
    "So in our example, the halting probabilities would be 0.1, 0.3, 0.6, since the last halting unit was 0.5 it pushed the accumulation of h above the 1 - epsilon threshold, so it's halting probability gets set to the remainder R(t). This way, the halting probabilities p are a probability distribution over the all the updates for that timestep t. The authors call this process of computing updates, pondering.\n",
    "\n",
    "<img src=\"https://miro.medium.com/max/1972/1*5dULqBM2KKGlQTHrKCeR3Q.png\" width=600>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Limiting Computation Time\n",
    "\n",
    "If the loss function,  L(x,y), ie binary cross entropy for the parity task, only rewards correct predictions and punishes wrong predictions, the ACT-RNN is encouraged to update the state as long as possible, to ponder infinitely long.\n",
    "\n",
    "We want the network to ponder longer for timesteps when this is beneficial, but also not to waste computation when a small number of updates can predict correctly. \n",
    "\n",
    "To encourage efficient use of computation, the *Ponder Cost* is added to the loss function and scaled by the *time penalty* (*Tau*)\n",
    "\n",
    "$$\\hat{L}(x,y) = L(x,y) + \\tau P(x) $$\n",
    "\n",
    "$$ P(x) = \\sum^{T}_{t=1} N(t) + R(t) $$\n",
    "\n",
    "The example implementation simplifies the Ponder Cost to:\n",
    "\n",
    "$$ P(x) = \\sum^{T}_{t=1} \\sum^{N(t)}_{n=1} - h^{n}_{t}  $$\n",
    "\n",
    "Which encourages the network to produce larger halting units to bring down the ponder cost.\n",
    "\n",
    "In early training, before this loss has been allowed to train the network to be parsimonious when pondering/allowing more updates, the halting bias b_n can be initialized to a positive scalar. \n",
    "\n",
    "$$ h^{n}_{t} = \\sigma(W_{h}s^{n}_{t} + b_{n}) $$\n",
    "\n",
    "Also, a hard limit on the number of updates, M, is used during implementation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation\n",
    "\n",
    "This is not an exhaustive implementation of ACT, it is a distilled version of this [GitHub](https://github.com/zphang/adaptive-computation-time-pytorch) that is complete enough only to concretely demonstrate how ACT processes the input, infers and is trained\n",
    "\n",
    "The task is the parity task\n",
    "\n",
    "<img src=\"https://media.arxiv-vanity.com/render-output/1687679/fig/parity_example.png\" width=200>\n",
    "\n",
    "Parity training Example. Each sequence consists of a single input and target vector. Similar to the example diagram we use a vector size 8, but in the paper the vector size was 64. To find the parity, just count to number of 1.'s, ignore the -1.'s and 0.'s, if there is an odd number of 1.'s the parity is 1, if there is an even number of 1.'s, the parity is 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "\n",
    "from utils import ParityDataManager, test_epoch,  maybe_cuda_var, bool_to_idx\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "config = Config()\n",
    "config.input_length = 8 \n",
    "config.test_percentage = 0.1 \n",
    "config.batch_size = 2 \n",
    "config.num_epochs = 10\n",
    "config.model_save_interval = 10\n",
    "config.model_save_path = \"models/parity/act_cpu\" #\"models/parity/act\"\n",
    "config.cuda =  False #True #\n",
    "config.act_ponder_penalty = 0.0001\n",
    "config.train_log = True\n",
    "config.train_log_interval = 10\n",
    "config.learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ACT(nn.Module):\n",
    "    \n",
    "    def __init__(self, rnn_size, input_size, \n",
    "                 max_ponder=100, epsilon=0.01):\n",
    "        \n",
    "        super(ACT, self).__init__()\n",
    "\n",
    "        self.max_ponder = max_ponder\n",
    "        self.epsilon = epsilon\n",
    "        self.input_size = input_size\n",
    "        self.rnn_size = rnn_size\n",
    "        \n",
    "        self.rnn = nn.RNNCell(\n",
    "            # input_size +1 for binary flag\n",
    "            input_size=self.input_size + 1,  \n",
    "            hidden_size=self.rnn_size,\n",
    "        )\n",
    "        \n",
    "        self.ponder_linear = nn.Linear(self.rnn.hidden_size, 1)\n",
    "        self.fc1 = nn.Linear(self.rnn_size, 1)\n",
    "        self.reset_parameters()\n",
    "        \n",
    "    def forward(self, input_, compute_ponder_cost=True):\n",
    "        \"\"\"\n",
    "        This forward pass takes an input of shape (batch_size, sequence length, input_dim)\n",
    "        A boolean that is True during training and False during testing. This is used\n",
    "        to pass the ponder cost to the overall loss function and incentivize efficient use\n",
    "        of compute. \n",
    "        \n",
    "        It puts the mean-field state through an affine layer to produce a logit for each sample\n",
    "        called all_s which is shape (batch_size), it also outputs a list with keys\n",
    "        \"ponder_cost\", \"ponder_times\" which are the scalar ponder costs, shape (batch_size),\n",
    "         and a list of the number of updates performed for each sample respectively\n",
    "        \"\"\"\n",
    "        #(batch_size, time, input_dim)->(time, batch_size, input_dim)\n",
    "        input_ = input_.transpose(0, 1) \n",
    "        \n",
    "        time_size, batch_size, input_dim_size = input_.size()\n",
    "    \n",
    "        # The initial hidden state s_0 \n",
    "        s = Variable(input_.data.new(batch_size, # (batch_size, hidden_size)\n",
    "                     self.rnn.hidden_size).zero_())\n",
    "            \n",
    "        selector = input_.data.new(batch_size).byte() # indices, ie [0, 1] uint8 shape [2]\n",
    "        \n",
    "        s_list = []\n",
    "        ponder_cost = 0\n",
    "        ponder_times = []\n",
    "\n",
    "        # For each timestep t: 1 thru T \n",
    "        for input_row in input_:\n",
    "            \n",
    "            accum_h = Variable(input_.data.new(batch_size).zero_())\n",
    "            accum_s = Variable(input_.data.new( # vector of zeros (batch size,hidden_dim)\n",
    "                       batch_size, self.rnn.hidden_size).zero_())\n",
    "\n",
    "            selector = selector.fill_(1) #ones shape (batch size)\n",
    "\n",
    "            step_count = Variable(input_.data.new(batch_size).zero_())\n",
    "\n",
    "            input_row_with_flag = torch.cat([\n",
    "                input_row,\n",
    "                Variable(input_row.data.new(batch_size, 1).zero_())\n",
    "            ], dim=1) # adds a 0 to the end of each input vector\n",
    "            # for x_1 this last element is 0, but for all others it is =1\n",
    "\n",
    "            if compute_ponder_cost:\n",
    "                step_ponder_cost = Variable(input_.data.new(batch_size).zero_())\n",
    "\n",
    "            # START LOOP for State Updates (1 thru N(t), per time step t)\n",
    "            for act_step in range(self.max_ponder): # 100\n",
    "                \n",
    "                # [1,1,1]->[0,1,2], [1,0]->[0], [0,1,1]->[1,2]\n",
    "                idx = bool_to_idx(selector)\n",
    "                \n",
    "                if compute_ponder_cost:\n",
    "                    # incentivize large halting units \n",
    "                    step_ponder_cost[idx] = -accum_h[idx]\n",
    "                    #print(\"step_ponder_cost\", step_ponder_cost)\n",
    "\n",
    "                # only update those hidden states for which the selector=1\n",
    "                s[idx] = self.rnn(input_row_with_flag[idx], s[idx])\n",
    "                \n",
    "                # halting units from the state \n",
    "                h =  torch.sigmoid(self.ponder_linear(s[idx]).squeeze(1))\n",
    "                accum_h[idx] += h # accumulate halting units \n",
    "                \n",
    "                # halting probability, if accum_h is < 1, p = h, if the most recent h has\n",
    "                # pushed accum_h over 1, set p to the remainder rather than h \n",
    "                p = h - (accum_h[idx] - 1).clamp(min=0) \n",
    "\n",
    "                # accumulate the mean-field of states weighted by the halting probability\n",
    "                accum_s[idx] += p.unsqueeze(1) * s[idx]  \n",
    "\n",
    "                step_count[idx] += 1 #keep track of total number of updates for this sample\n",
    "                \n",
    "                # prune the batch to include only samples that have not exceeded computational budget \n",
    "                selector = (accum_h < 1 - self.epsilon).data \n",
    "                if not selector.any(): # if all selectors == False, done processing s\n",
    "                    break\n",
    "                    \n",
    "                #change last element of input to 1 if after first pondering update\n",
    "                input_row_with_flag[:, input_dim_size] = 1 \n",
    "                \n",
    "                # END OF LOOP for State Updates (1 thru N(t), per time step t)\n",
    "            \n",
    "            # at each timestep, how many times was each sample in the batch processed \n",
    "            ponder_times.append(step_count.data.cpu().numpy())\n",
    "            \n",
    "            if compute_ponder_cost:\n",
    "                ponder_cost += step_ponder_cost\n",
    "        \n",
    "            # append once for each time step (only once in parity)\n",
    "            s_list.append(accum_s)\n",
    "            \n",
    "        # END OF LOOP for sequence length T \n",
    "        \n",
    "        all_s = torch.stack(s_list)\n",
    "        s = s.unsqueeze(0)\n",
    "        all_s = all_s.transpose(0, 1)\n",
    "        \n",
    "        ponder_cost = {\"ponder_cost\": ponder_cost, \"ponder_times\": ponder_times}\n",
    "        all_s = self.fc1(all_s).squeeze(1).squeeze(1)\n",
    "\n",
    "        return all_s, ponder_cost \n",
    "\n",
    "    def reset_parameters(self):\n",
    "        self.rnn.reset_parameters()\n",
    "        self.ponder_linear.reset_parameters()\n",
    "        self.ponder_linear.bias.data.fill_(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x tensor([[[-1.,  1.,  1., -1., -1.,  0.,  0.,  0.]],\n",
      "\n",
      "        [[-1., -1.,  0.,  0.,  0.,  0.,  0.,  0.]]]) torch.Size([2, 1, 8])\n",
      "y tensor([ 0.,  0.]) torch.Size([2])\n",
      "____________________________________________\n",
      "____________________________________________\n",
      "y_hat tensor([ 0.1588,  0.0086]) ponder_dict [array([2., 2.], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "model = ACT(rnn_size = 16, input_size = config.input_length)\n",
    "\n",
    "if config.cuda:\n",
    "    model = model.cuda()\n",
    "\n",
    "data_manager = ParityDataManager\n",
    "test_data_loader = data_manager.create_dataloader(config, mode=\"test\")\n",
    "\n",
    "for batch_idx, (x, y) in enumerate(test_data_loader):\n",
    "    \n",
    "    x_var = maybe_cuda_var(x, cuda=config.cuda)\n",
    "    y_var = Variable(y, requires_grad=False)\n",
    "    if config.cuda:\n",
    "        y_var = y_var.cuda()\n",
    "    \n",
    "    print(\"x\", x_var, x_var.shape)\n",
    "    print(\"y\", y_var, y_var.shape)\n",
    "    print(\"____________________________________________\")\n",
    "    break\n",
    "    \n",
    "y_hat, ponder_dict = model(x_var)\n",
    "print(\"____________________________________________\")\n",
    "print(\"y_hat\", y_hat, \"ponder_dict\", ponder_dict[\"ponder_times\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/160 (0%)]\tLoss: 0.276837\n",
      "Train Epoch: 1 [20/160 (12%)]\tLoss: 0.717690\n",
      "Train Epoch: 1 [40/160 (25%)]\tLoss: 0.716756\n",
      "Train Epoch: 1 [60/160 (38%)]\tLoss: 0.066146\n",
      "Train Epoch: 1 [80/160 (50%)]\tLoss: 0.082953\n",
      "Train Epoch: 1 [100/160 (62%)]\tLoss: 0.260558\n",
      "Train Epoch: 1 [120/160 (75%)]\tLoss: 0.082243\n",
      "Train Epoch: 1 [140/160 (88%)]\tLoss: 0.007279\n",
      "Epoch: 1, Average loss: 0.2680, Accuracy: 13/16 (81%), PT: 18.2\n",
      "Train Epoch: 2 [0/160 (0%)]\tLoss: 0.069718\n",
      "Train Epoch: 2 [20/160 (12%)]\tLoss: 0.079636\n",
      "Train Epoch: 2 [40/160 (25%)]\tLoss: 0.662489\n",
      "Train Epoch: 2 [60/160 (38%)]\tLoss: 0.093592\n",
      "Train Epoch: 2 [80/160 (50%)]\tLoss: 0.012440\n",
      "Train Epoch: 2 [100/160 (62%)]\tLoss: 0.152054\n",
      "Train Epoch: 2 [120/160 (75%)]\tLoss: 0.699354\n",
      "Train Epoch: 2 [140/160 (88%)]\tLoss: 0.006399\n",
      "Epoch: 2, Average loss: 0.0090, Accuracy: 16/16 (100%), PT: 9.8\n",
      "Train Epoch: 3 [0/160 (0%)]\tLoss: 0.124575\n",
      "Train Epoch: 3 [20/160 (12%)]\tLoss: 0.961961\n",
      "Train Epoch: 3 [40/160 (25%)]\tLoss: 0.084612\n",
      "Train Epoch: 3 [60/160 (38%)]\tLoss: 0.474289\n",
      "Train Epoch: 3 [80/160 (50%)]\tLoss: 0.006539\n",
      "Train Epoch: 3 [100/160 (62%)]\tLoss: 0.005755\n",
      "Train Epoch: 3 [120/160 (75%)]\tLoss: 0.104031\n",
      "Train Epoch: 3 [140/160 (88%)]\tLoss: 0.069719\n",
      "Epoch: 3, Average loss: 0.1034, Accuracy: 14/16 (88%), PT: 27.2\n",
      "Train Epoch: 4 [0/160 (0%)]\tLoss: 0.074348\n",
      "Train Epoch: 4 [20/160 (12%)]\tLoss: 0.464156\n",
      "Train Epoch: 4 [40/160 (25%)]\tLoss: 0.254906\n",
      "Train Epoch: 4 [60/160 (38%)]\tLoss: 0.025819\n",
      "Train Epoch: 4 [80/160 (50%)]\tLoss: 0.185501\n",
      "Train Epoch: 4 [100/160 (62%)]\tLoss: 0.022360\n",
      "Train Epoch: 4 [120/160 (75%)]\tLoss: 0.059362\n",
      "Train Epoch: 4 [140/160 (88%)]\tLoss: 0.026600\n",
      "Epoch: 4, Average loss: 0.1550, Accuracy: 13/16 (81%), PT: 30.8\n",
      "Train Epoch: 5 [0/160 (0%)]\tLoss: 0.006356\n",
      "Train Epoch: 5 [20/160 (12%)]\tLoss: 0.119315\n",
      "Train Epoch: 5 [40/160 (25%)]\tLoss: 0.861784\n",
      "Train Epoch: 5 [60/160 (38%)]\tLoss: 0.398374\n",
      "Train Epoch: 5 [80/160 (50%)]\tLoss: 0.006969\n",
      "Train Epoch: 5 [100/160 (62%)]\tLoss: 0.153988\n",
      "Train Epoch: 5 [120/160 (75%)]\tLoss: 0.004733\n",
      "Train Epoch: 5 [140/160 (88%)]\tLoss: 0.005017\n",
      "Epoch: 5, Average loss: 0.0862, Accuracy: 14/16 (88%), PT: 12.4\n",
      "Train Epoch: 6 [0/160 (0%)]\tLoss: 0.106674\n",
      "Train Epoch: 6 [20/160 (12%)]\tLoss: 0.053891\n",
      "Train Epoch: 6 [40/160 (25%)]\tLoss: 0.011035\n",
      "Train Epoch: 6 [60/160 (38%)]\tLoss: 0.080043\n",
      "Train Epoch: 6 [80/160 (50%)]\tLoss: 0.410291\n",
      "Train Epoch: 6 [100/160 (62%)]\tLoss: 0.058819\n",
      "Train Epoch: 6 [120/160 (75%)]\tLoss: 0.118809\n",
      "Train Epoch: 6 [140/160 (88%)]\tLoss: 0.006450\n",
      "Epoch: 6, Average loss: 0.0450, Accuracy: 15/16 (94%), PT: 12.0\n",
      "Train Epoch: 7 [0/160 (0%)]\tLoss: 0.010613\n",
      "Train Epoch: 7 [20/160 (12%)]\tLoss: 0.284163\n",
      "Train Epoch: 7 [40/160 (25%)]\tLoss: 0.067392\n",
      "Train Epoch: 7 [60/160 (38%)]\tLoss: 0.350719\n",
      "Train Epoch: 7 [80/160 (50%)]\tLoss: 0.051423\n",
      "Train Epoch: 7 [100/160 (62%)]\tLoss: 0.004431\n",
      "Train Epoch: 7 [120/160 (75%)]\tLoss: 0.387809\n",
      "Train Epoch: 7 [140/160 (88%)]\tLoss: 0.004589\n",
      "Epoch: 7, Average loss: 0.0332, Accuracy: 15/16 (94%), PT: 20.2\n",
      "Train Epoch: 8 [0/160 (0%)]\tLoss: 0.066143\n",
      "Train Epoch: 8 [20/160 (12%)]\tLoss: 0.003335\n",
      "Train Epoch: 8 [40/160 (25%)]\tLoss: 0.442168\n",
      "Train Epoch: 8 [60/160 (38%)]\tLoss: 0.004681\n",
      "Train Epoch: 8 [80/160 (50%)]\tLoss: 0.045619\n",
      "Train Epoch: 8 [100/160 (62%)]\tLoss: 0.034447\n",
      "Train Epoch: 8 [120/160 (75%)]\tLoss: 0.005708\n",
      "Train Epoch: 8 [140/160 (88%)]\tLoss: 0.046778\n",
      "Epoch: 8, Average loss: 0.1200, Accuracy: 14/16 (88%), PT: 9.9\n",
      "Train Epoch: 9 [0/160 (0%)]\tLoss: 0.054489\n",
      "Train Epoch: 9 [20/160 (12%)]\tLoss: 0.032307\n",
      "Train Epoch: 9 [40/160 (25%)]\tLoss: 0.914604\n",
      "Train Epoch: 9 [60/160 (38%)]\tLoss: 0.338369\n",
      "Train Epoch: 9 [80/160 (50%)]\tLoss: 0.039883\n",
      "Train Epoch: 9 [100/160 (62%)]\tLoss: 0.036248\n",
      "Train Epoch: 9 [120/160 (75%)]\tLoss: 0.003673\n",
      "Train Epoch: 9 [140/160 (88%)]\tLoss: 0.028120\n",
      "Epoch: 9, Average loss: 0.0677, Accuracy: 15/16 (94%), PT: 20.7\n",
      "Train Epoch: 10 [0/160 (0%)]\tLoss: 0.374248\n",
      "Train Epoch: 10 [20/160 (12%)]\tLoss: 0.004488\n",
      "Train Epoch: 10 [40/160 (25%)]\tLoss: 0.060793\n",
      "Train Epoch: 10 [60/160 (38%)]\tLoss: 0.003935\n",
      "Train Epoch: 10 [80/160 (50%)]\tLoss: 0.033303\n",
      "Train Epoch: 10 [100/160 (62%)]\tLoss: 0.004807\n",
      "Train Epoch: 10 [120/160 (75%)]\tLoss: 0.036180\n",
      "Train Epoch: 10 [140/160 (88%)]\tLoss: 0.003937\n",
      "Epoch: 10, Average loss: 0.0306, Accuracy: 15/16 (94%), PT: 19.6\n",
      "Saving checkpoint to models/parity/act_cpu/epoch_10.pt\n"
     ]
    }
   ],
   "source": [
    "loss_func = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=config.learning_rate)\n",
    "\n",
    "for epoch in range(1, config.num_epochs + 1):\n",
    "    train_data_loader = data_manager.create_dataloader(config)\n",
    "    test_data_loader = data_manager.create_dataloader(config, mode=\"test\")\n",
    "\n",
    "    for batch_idx, (x, y) in enumerate(train_data_loader):\n",
    "        \n",
    "        x_var = maybe_cuda_var(x, cuda=config.cuda)\n",
    "        y_var = Variable(y, requires_grad=False)\n",
    "        \n",
    "        if config.cuda:\n",
    "            y_var = y_var.cuda()\n",
    "\n",
    "        y_hat, ponder_dict = model(x_var) # Forward pass \n",
    "        \n",
    "        loss = loss_func(y_hat, y_var) #BCE Loss\n",
    "        if ponder_dict: # add Ponder Cost to BCE Loss \n",
    "            loss += (\n",
    "                config.act_ponder_penalty * ponder_dict[\"ponder_cost\"].mean()\n",
    "            )\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward() # backprop\n",
    "        optimizer.step() # update weights\n",
    "\n",
    "        if config.train_log and batch_idx % config.train_log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(x), len(train_data_loader.dataset),\n",
    "                100. * batch_idx / len(train_data_loader), loss.item())\n",
    "            )\n",
    "    \n",
    "    test_result = test_epoch(\n",
    "        config=config, model=model,\n",
    "        data_loader=test_data_loader,\n",
    "        epoch=epoch,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x tensor([[[-1.,  1.,  1.,  0.,  0.,  0.,  0.,  0.]],\n",
      "\n",
      "        [[-1.,  1.,  1.,  1.,  1.,  1.,  0.,  0.]]]) torch.Size([2, 1, 8])\n",
      "y tensor([ 0.,  1.]) torch.Size([2])\n",
      "____________________________________________\n",
      "____________________________________________\n",
      "y_hat tensor([-5.2169,  2.4202]) ponder_dict [array([11.,  4.], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "model = ACT(rnn_size = 16, input_size = config.input_length)\n",
    "\n",
    "if config.cuda:\n",
    "    model = model.cuda()\n",
    "\n",
    "epoch = 10\n",
    "model_save_path = pathlib.Path(config.model_save_path)\n",
    "model_save_file_path = (\n",
    "    model_save_path / f\"epoch_{epoch}.pt\"\n",
    ")\n",
    "model.load_state_dict(torch.load(model_save_file_path))\n",
    "\n",
    "data_manager = ParityDataManager\n",
    "test_data_loader = data_manager.create_dataloader(config, mode=\"test\")\n",
    "\n",
    "for batch_idx, (x, y) in enumerate(test_data_loader):\n",
    "    \n",
    "    x_var = maybe_cuda_var(x, cuda=config.cuda)\n",
    "    y_var = Variable(y, requires_grad=False)\n",
    "    if config.cuda:\n",
    "        y_var = y_var.cuda()\n",
    "    \n",
    "    print(\"x\", x_var, x_var.shape)\n",
    "    print(\"y\", y_var, y_var.shape)\n",
    "    print(\"____________________________________________\")\n",
    "    break\n",
    "    \n",
    "y_hat, ponder_dict = model(x_var)\n",
    "print(\"____________________________________________\")\n",
    "print(\"y_hat\", y_hat, \"ponder_dict\", ponder_dict[\"ponder_times\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parity Task \n",
    "\n",
    "The RNN used was a single layer vanilla RNN with hidden size 128\n",
    "\n",
    "<img src=\"https://media.arxiv-vanity.com/render-output/1687679/fig/parity_bar.png\">\n",
    "\n",
    "Parity Error Rates. Bar heights show the mean error rates for different time penalties at the end of training. The error bars show the standard error in the mean.\n",
    "\n",
    "<img src=\"https://media.arxiv-vanity.com/render-output/1687679/fig/parity_plot.png\">\n",
    "\n",
    "Parity Learning Curves and Error Rates Versus Ponder Time. Left: Errors for each \n",
    "τ value. ‘Iterations’ is the number of gradient updates per asynchronous worker. Right: Small circles represent individual runs after training is complete, large circles represent the mean over 20 runs for each  τ value. ‘Ponder’ is the mean number of computation steps per input timestep (minimum 1). The black dotted line shows the mean error for the networks without ACT. The height of the ellipses surrounding the mean values represents the standard error over error rates for that value of τ, while the width shows the standard error over ponder times.\n",
    "\n",
    "<img src=\"https://media.arxiv-vanity.com/render-output/1687679/fig/parity_difficulty.png\">\n",
    "\n",
    "Parity Ponder Time and Error Rate Versus Input Difficulty. Faint lines are individual runs, bold lines are means over 20 networks. ‘Difficulty’ is the number of bits in the parity vectors, with a mean over 1,000 random vectors used for each data-point."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logic Task \n",
    "\n",
    "The RNN used was a single layer LSTM with hidden size 128\n",
    "\n",
    "<img src=\"https://media.arxiv-vanity.com/render-output/1687679/fig/logic_example.png\">\n",
    "\n",
    "The first input sequence has input bits b_0 = F, b_1 = T. The first gate these two bits are operated on is the NOR gate, onehot encoded by 100. The output of this gate is b_2 = F, b_1 = F and b_2 = F are operated on by the next gate, 010, which is the Xq gate. The Binary Truth Table shows that for Xq, F,F->F therefore b_3 = F and thus the target is 0 for this first input vector. \n",
    "\n",
    "<img src=\"https://media.arxiv-vanity.com/render-output/1687679/fig/logic_bar.png\">\n",
    "\n",
    "\n",
    "<img src=\"https://media.arxiv-vanity.com/render-output/1687679/fig/logic_plot.png\">\n",
    "\n",
    "network reaches a minimum sequence error rate of around 0.2 without ACT (compared to 0.5 for random guessing)\n",
    "\n",
    "<img src=\"https://media.arxiv-vanity.com/render-output/1687679/fig/logic_difficulty.png\">\n",
    "\n",
    "Logic Ponder Time and Error Rate Versus Input Difficulty. The example pretends there are 2 gates in sequence and 3 choices for each gate. The experiment in the paper has 10 gates and 10 choices of gates for each. ‘Difficulty’ is the number of logic gates in each input vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Addition Task\n",
    "\n",
    "<img src=\"https://media.arxiv-vanity.com/render-output/1687679/fig/addition_example.png\" width=300>\n",
    "\n",
    "The example performs the addition operations: 1038 + 392 = 1430, 68450 + 1430 = 69880\n",
    "\n",
    "Each of those digits is actually onehot encoded and concatenated into the input vector. Since there are 5 digits with and 10 choices for each digit, the input vector is size 50.\n",
    "\n",
    "<img src=\"https://media.arxiv-vanity.com/render-output/1687679/fig/addition_bar.png\">\n",
    "\n",
    "<img src=\"https://media.arxiv-vanity.com/render-output/1687679/fig/addition_plot.png\">\n",
    "\n",
    "<img src=\"https://media.arxiv-vanity.com/render-output/1687679/fig/addition_difficulty.png\">\n",
    "The relationship between the ponder time and the number of digits (Difficulty) was approximately linear for most of the ACT networks\n",
    "<img src=\"https://media.arxiv-vanity.com/render-output/1687679/fig/addition_sequence_wide_lines.png\">\n",
    "\n",
    "The grey lines show the total number of digits in the two numbers being summed at each step; this appears to give a rough lower bound on the ponder time, suggesting an internal algorithm that is approximately linear in the number of digits."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sort Task\n",
    "\n",
    "Here the size 2 vectors, ie `[0, -0.03]`, are fed one at a time. The first element becomes 1 when it is the last value to be sorted `[1, 0.55]`. Up to 15 of these sequences are fed before the outputs start to be considered. Thereafter, the outputs are size 15 softmax classifiers to predict the indices of the 15 inputs in ascending order. \n",
    "\n",
    "<img src=\"https://media.arxiv-vanity.com/render-output/1687679/fig/sort_example.png\" width=500>\n",
    "\n",
    "<img src=\"https://media.arxiv-vanity.com/render-output/1687679/fig/sort_bar.png\">\n",
    "\n",
    "<img src=\"https://media.arxiv-vanity.com/render-output/1687679/fig/sort_plot.png\">\n",
    "\n",
    "<img src=\"https://media.arxiv-vanity.com/render-output/1687679/fig/sort_difficulty.png\">\n",
    "\n",
    "<img src=\"https://media.arxiv-vanity.com/render-output/1687679/fig/sort_sequence_3_black.png\">\n",
    "\n",
    "There is a large spike in ponder time near (though not precisely at) the end of the input sequence, presumably when the majority of the sort comparisons take place. The spike is much higher for the longer sequences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wikipedia Character prediction\n",
    "\n",
    "Language modeling was performed on raw unicode text. LSTM networks were used with a single layer of 1500 cells and a size 256 softmax classification layer to predict the next n+1 byte in the sequence\n",
    "\n",
    "<img src=\"https://media.arxiv-vanity.com/render-output/1687679/fig/enwik_bar.png\">\n",
    "Error rates are fairly similar with and without ACT\n",
    "<img src=\"https://media.arxiv-vanity.com/render-output/1687679/fig/enwik_plot.png\">\n",
    "Learning curves suggest that the ACT networks are somewhat more data efficient. The amount of ponder per input is much lower than for the other problems, suggesting that the advantages of extra computation were slight for this task.\n",
    "<img src=\"https://media.arxiv-vanity.com/render-output/1687679/fig/enwik_sequence.png\">\n",
    "Ponder Time, Prediction loss and Prediction Entropy During a Wikipedia Text Sequence.\n",
    "Character prediction networks trained with ACT consistently pause at spaces between words, and pause for longer at ‘boundary’ characters such as commas and full stops. We speculate that the extra computation is used to make predictions about the next ‘chunk’ in the data (word, sentence, clause)\n",
    "<img src=\"https://media.arxiv-vanity.com/render-output/1687679/fig/enwik_sequence_2.png\">\n",
    "Ponder Time, Prediction loss and Prediction Entropy During a Wikipedia Sequence Containing XML Tags. Again ACT is an effective detector of non-text transition markers such as the opening brackets of XML tags, ACT does not increase computation time during random or fundamentally unpredictable sequences like the two ID numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion \n",
    "\n",
    "ACT allows RNNS to dynamically adapt the amount of computation it uses to the demands of the data. An experiment on real data suggests that the allocation of computation steps learned by ACT can yield insight into both the structure of the data and the computational demands of predicting it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
